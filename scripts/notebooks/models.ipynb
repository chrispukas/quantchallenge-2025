{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017337e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D         E         F         G  \\\n",
      "0  0.128342 -0.150355 -0.627005 -0.585210 -0.256904 -0.002869 -0.458575   \n",
      "1  0.111149 -0.252733  0.042513 -0.556067 -0.127410 -0.232383  0.027353   \n",
      "2 -0.197761 -0.554981 -0.211682 -0.744126 -0.177530 -0.493903 -0.082152   \n",
      "3  0.129840 -0.296321  0.509336 -0.567932  0.716634 -0.344869  0.735615   \n",
      "4  0.022574 -0.342591  0.172240 -0.686743 -0.155533 -0.167701 -0.237098   \n",
      "\n",
      "          H         I         J  ...  K_neg    L_diff  L_pos  L_neg    M_diff  \\\n",
      "0 -1.425916 -0.378180 -0.661343  ...      1  0.000001      0      1 -0.000002   \n",
      "1  0.092018 -0.552405 -0.248102  ...      1 -0.235708      0      1  0.428053   \n",
      "2  0.675504 -0.632501  0.194827  ...      1 -0.304842      0      1  0.251707   \n",
      "3  1.312159 -0.426990  0.517681  ...      1  0.209939      0      1  0.239458   \n",
      "4  0.832055 -0.681470 -0.259371  ...      1 -0.073024      0      1 -0.321842   \n",
      "\n",
      "   M_pos  M_neg    N_diff  N_pos  N_neg  \n",
      "0      0      1 -0.000003      0      1  \n",
      "1      0      1  0.550895      1      0  \n",
      "2      1      0  0.078467      1      0  \n",
      "3      1      0  0.229390      1      0  \n",
      "4      1      0 -0.319696      1      0  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
      "       'Y1', 'Y2', 'O', 'P', 'A_diff', 'A_pos', 'A_neg', 'B_diff', 'B_pos',\n",
      "       'B_neg', 'C_diff', 'C_pos', 'C_neg', 'D_diff', 'D_pos', 'D_neg',\n",
      "       'E_diff', 'E_pos', 'E_neg', 'F_diff', 'F_pos', 'F_neg', 'G_diff',\n",
      "       'G_pos', 'G_neg', 'H_diff', 'H_pos', 'H_neg', 'I_diff', 'I_pos',\n",
      "       'I_neg', 'J_diff', 'J_pos', 'J_neg', 'K_diff', 'K_pos', 'K_neg',\n",
      "       'L_diff', 'L_pos', 'L_neg', 'M_diff', 'M_pos', 'M_neg', 'N_diff',\n",
      "       'N_pos', 'N_neg'],\n",
      "      dtype='object')\n",
      "torch.Size([80000, 58])\n",
      "torch.Size([80000, 2])\n",
      "Out of range by: 4 items!\n",
      "Out of range by: 8 items!\n",
      "Out of range by: 12 items!\n",
      "Out of range by: 16 items!\n",
      "Out of range by: 20 items!\n",
      "Out of range by: 24 items!\n",
      "Out of range by: 28 items!\n",
      "Out of range by: 32 items!\n",
      "Out of range by: 36 items!\n",
      "Out of range by: 40 items!\n",
      "Out of range by: 44 items!\n",
      "Out of range by: 48 items!\n",
      "Out of range by: 52 items!\n",
      "Out of range by: 56 items!\n",
      "Out of range by: 60 items!\n",
      "Out of range by: 64 items!\n",
      "Out of range by: 68 items!\n",
      "Out of range by: 72 items!\n",
      "Out of range by: 76 items!\n",
      "Out of range by: 80 items!\n",
      "Out of range by: 84 items!\n",
      "Out of range by: 88 items!\n",
      "Out of range by: 92 items!\n",
      "Out of range by: 96 items!\n",
      "Out of range by: 100 items!\n",
      "Out of range by: 104 items!\n",
      "Out of range by: 108 items!\n",
      "Out of range by: 112 items!\n",
      "Out of range by: 116 items!\n",
      "Out of range by: 120 items!\n",
      "Out of range by: 124 items!\n",
      "Initialized dataset torch.Size([20000, 128, 58]) torch.Size([20000, 128, 2])\n",
      "[2025-09-21 20:11:53.300404] Current batch item: 0, took 222 ms, current loss: 0.8167352676391602, mean loss: 0.8167352676391602\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     27\u001b[39m train_dataset = DS(dataset_path=\u001b[33m\"\u001b[39m\u001b[33m/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/train.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m                    dataset_path_2=\u001b[33m\"\u001b[39m\u001b[33m/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/train_new.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m                         window_size=window_size,\n\u001b[32m     30\u001b[39m                         window_steps=window_steps,\n\u001b[32m     31\u001b[39m                         dtype=dtype)\n\u001b[32m     33\u001b[39m rnn = network.RNN(\u001b[32m58\u001b[39m, \u001b[32m1024\u001b[39m, \u001b[32m3\u001b[39m, dropout, attn_heads, \u001b[32m2\u001b[39m, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m), dtype=dtype)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m losses = \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mr2_priority\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m#plt.plot_line(np.arange(1, len(losses)+1), losses)\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m#checkpoint = torch.load(\"/home/ubuntu/repos/quantchallenge-2025/weights/weights.pth\", weights_only=True)\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m#rnn.load_state_dict(checkpoint['model_state_dict'])\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28meval\u001b[39m = DS(dataset_path=\u001b[33m\"\u001b[39m\u001b[33m/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/test.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m           dataset_path_2=\u001b[33m\"\u001b[39m\u001b[33m/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/test_new.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m                     window_size=window_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m                     device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     48\u001b[39m                     dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/quantchallenge-2025/qch2025/pkg/models/RNN/func.py:41\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataset, epochs, batch_size, decay, learning_rate)\u001b[39m\n\u001b[32m     38\u001b[39m optimizer.step()\n\u001b[32m     39\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m losses.append(\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m250\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.datetime.now()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Current batch item: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m((time.datetime.now()-t).total_seconds()*\u001b[32m1000\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ms, current loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, mean loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(np.array(losses))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from qch2025.pkg.models.RNN import network as network\n",
    "from qch2025.pkg.models.RNN import func as func\n",
    "\n",
    "from qch2025.pkg.dataset import DS\n",
    "\n",
    "import qch2025.pkg.plotting as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "n_epochs = 35\n",
    "window_size = 128\n",
    "batch_size = 32\n",
    "window_steps = 4 # Minimize the overlap\n",
    "attn_heads = 4\n",
    "\n",
    "learning_rate = 0.0001\n",
    "dropout = 0.1\n",
    "\n",
    "r2_priority = 0.1\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "# Training\n",
    "train_dataset = DS(dataset_path=\"/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/train.csv\",\n",
    "                   dataset_path_2=\"/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/train_new.csv\",\n",
    "                        window_size=window_size,\n",
    "                        window_steps=window_steps,\n",
    "                        dtype=dtype)\n",
    "\n",
    "rnn = network.RNN(58, 1024, 3, dropout, attn_heads, 2, device=torch.device(\"cuda\"), dtype=dtype)\n",
    "losses = func.train(rnn, dataset=train_dataset, epochs=n_epochs, learning_rate=learning_rate, decay=r2_priority)\n",
    "\n",
    "#plt.plot_line(np.arange(1, len(losses)+1), losses)\n",
    "\n",
    "\n",
    "#checkpoint = torch.load(\"/home/ubuntu/repos/quantchallenge-2025/weights/weights.pth\", weights_only=True)\n",
    "#rnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "eval = DS(dataset_path=\"/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/test.csv\",\n",
    "          dataset_path_2=\"/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/test_new.csv\",\n",
    "                    window_size=window_size,\n",
    "                    window_steps=window_size,\n",
    "                    eval=True,\n",
    "                    device=torch.device(\"cuda\"),\n",
    "                    dtype=dtype)\n",
    "y1, y2 = func.eval(rnn, eval, batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Y1\": y1, \"Y2\": y2})\n",
    "df.index.name=\"id\"\n",
    "df.index= df.index + 1\n",
    "\n",
    "actual = len(eval.df[\"A\"])\n",
    "df1_trunc = df.head(actual)\n",
    "\n",
    "df1_trunc.to_csv(f\"/home/ubuntu/repos/quantchallenge-2025/qch2025/outputs/{datetime.datetime.now()}_predicted.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154d515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7b387",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RNN:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([2048, 14]) from checkpoint, the shape in current model is torch.Size([2048, 15]).\n\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([2048, 14]) from checkpoint, the shape in current model is torch.Size([2048, 15]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m rnn = network.RNN(\u001b[32m15\u001b[39m, \u001b[32m512\u001b[39m, \u001b[32m2\u001b[39m, dropout, attn_heads, \u001b[32m2\u001b[39m, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m), dtype=dtype)\n\u001b[32m     29\u001b[39m checkpoint = torch.load(\u001b[33m\"\u001b[39m\u001b[33m/home/ubuntu/repos/quantchallenge-2025/weights/weights.pth\u001b[39m\u001b[33m\"\u001b[39m, weights_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_state_dict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28meval\u001b[39m = DS(dataset_path=\u001b[33m\"\u001b[39m\u001b[33m/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/test.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m                     window_size=window_size,\n\u001b[32m     34\u001b[39m                     window_steps=\u001b[32m1\u001b[39m,\n\u001b[32m     35\u001b[39m                     \u001b[38;5;28meval\u001b[39m=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     36\u001b[39m                     device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     37\u001b[39m                     dtype=dtype)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28meval\u001b[39m.ids.shape, \u001b[38;5;28meval\u001b[39m.train.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/qch/lib/python3.13/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for RNN:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([2048, 14]) from checkpoint, the shape in current model is torch.Size([2048, 15]).\n\tsize mismatch for lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([2048, 14]) from checkpoint, the shape in current model is torch.Size([2048, 15])."
     ]
    }
   ],
   "source": [
    "from qch2025.pkg.models.RNN import network as network\n",
    "from qch2025.pkg.models.RNN import func as func\n",
    "\n",
    "from qch2025.pkg.dataset import DS\n",
    "\n",
    "import qch2025.pkg.plotting as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "n_epochs = 30\n",
    "window_size = 128\n",
    "batch_size = 32\n",
    "window_steps = 4\n",
    "attn_heads = 2\n",
    "\n",
    "learning_rate = 0.0005\n",
    "dropout = 0.05\n",
    "\n",
    "r2_priority = 0.1\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "rnn = network.RNN(15, 512, 2, dropout, attn_heads, 2, device=torch.device(\"cuda\"), dtype=dtype)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(\"/home/ubuntu/repos/quantchallenge-2025/weights/weights.pth\", weights_only=True)\n",
    "rnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "eval = DS(dataset_path=\"/home/ubuntu/repos/quantchallenge-2025/qch2025/dataset/test.csv\",\n",
    "                    window_size=window_size,\n",
    "                    window_steps=1,\n",
    "                    eval=True,\n",
    "                    device=torch.device(\"cuda\"),\n",
    "                    dtype=dtype)\n",
    "print(eval.ids.shape, eval.train.shape)\n",
    "y1, y2 = func.eval(rnn, eval)\n",
    "\n",
    "ids = np.arrange(1, len(y1)+1)\n",
    "print(len(ids))\n",
    "print(len(y1), y1.shape)\n",
    "\n",
    "df = pd.DataFrame({\"Y1\": y1, \"Y2\": y2})\n",
    "df.index.name=\"id\"\n",
    "df.index= df.index + 1\n",
    "df.to_csv(f\"/home/ubuntu/repos/quantchallenge-2025/qch2025/outputs/{datetime.datetime.now()}_predicted.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
